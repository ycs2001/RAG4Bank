"""
è‡ªåŠ¨åŒ–æ–‡æ¡£å¤„ç†å·¥ä½œæµç¨‹ä¸»è„šæœ¬
æ•´åˆæ–‡æ¡£è½¬æ¢ã€æ–‡æœ¬åˆ†å—ã€Excelåˆ†å—ç­‰åŠŸèƒ½
"""

import sys
import logging
import argparse
import shutil
from pathlib import Path
from typing import Dict

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from document_converter import DocumentConverter
from text_chunker import TextChunker
from excel_chunker import ExcelChunker

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('document_processing.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class DocumentProcessingWorkflow:
    """æ–‡æ¡£å¤„ç†å·¥ä½œæµç¨‹ç±»"""

    def __init__(self, input_dir: str = "KnowledgeBase", output_base_dir: str = "processed_documents",
                 chunk_size: int = 5000, overlap_size: int = 1000):
        """
        åˆå§‹åŒ–å·¥ä½œæµç¨‹

        Args:
            input_dir: è¾“å…¥æ–‡æ¡£ç›®å½•
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
            chunk_size: æ–‡æœ¬åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            overlap_size: åˆ†å—é‡å å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
        """
        self.input_dir = Path(input_dir)
        self.output_base_dir = Path(output_base_dir)

        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„ï¼ˆç»Ÿä¸€åˆ‡å—æ–‡ä»¶å¤¹ï¼‰
        self.converted_dir = self.output_base_dir / "converted_markdown"
        self.chunks_dir = self.output_base_dir / "chunks"  # ç»Ÿä¸€çš„åˆ‡å—æ–‡ä»¶å¤¹

        # åˆ›å»ºæ‰€æœ‰è¾“å‡ºç›®å½•
        for dir_path in [self.converted_dir, self.chunks_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–å¤„ç†å™¨
        self.converter = DocumentConverter(str(self.converted_dir))
        self.text_chunker = TextChunker(chunk_size=chunk_size, overlap_size=overlap_size)
        self.excel_chunker = ExcelChunker(chunk_size=40)

        # å¤„ç†ç»“æœç»Ÿè®¡
        self.processing_stats = {
            'converted_files': 0,
            'text_chunks': 0,
            'excel_chunks': 0,
            'errors': []
        }

    def run_full_workflow(self) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„æ–‡æ¡£å¤„ç†å·¥ä½œæµç¨‹

        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        logger.info("å¼€å§‹æ‰§è¡Œæ–‡æ¡£å¤„ç†å·¥ä½œæµç¨‹")
        logger.info(f"è¾“å…¥ç›®å½•: {self.input_dir}")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_base_dir}")

        try:
            # ç¬¬é›¶é˜¶æ®µï¼šæ¸…ç†æ—§åˆ†å—æ–‡ä»¶
            logger.info("=" * 50)
            logger.info("ç¬¬é›¶é˜¶æ®µï¼šæ¸…ç†æ—§åˆ†å—æ–‡ä»¶")
            self._clean_old_chunks()

            # ç¬¬ä¸€é˜¶æ®µï¼šæ–‡æ¡£æ ¼å¼è½¬æ¢
            logger.info("=" * 50)
            logger.info("ç¬¬ä¸€é˜¶æ®µï¼šæ–‡æ¡£æ ¼å¼è½¬æ¢")
            conversion_results = self._convert_documents()

            # ç¬¬äºŒé˜¶æ®µï¼šæ–‡æ¡£åˆ†å—å¤„ç†
            logger.info("=" * 50)
            logger.info("ç¬¬äºŒé˜¶æ®µï¼šæ–‡æ¡£åˆ†å—å¤„ç†")
            self._process_chunks(conversion_results)

            # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            logger.info("=" * 50)
            logger.info("ç”Ÿæˆå¤„ç†æŠ¥å‘Š")
            try:
                self._generate_report()
            except Exception as e:
                logger.warning(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œä½†ä¸å½±å“ä¸»è¦åŠŸèƒ½: {str(e)}")
                # ä¸å°†æŠ¥å‘Šé”™è¯¯è®¡å…¥ä¸»è¦é”™è¯¯ç»Ÿè®¡

            logger.info("æ–‡æ¡£å¤„ç†å·¥ä½œæµç¨‹å®Œæˆ")
            return self.processing_stats

        except Exception as e:
            error_msg = f"å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self.processing_stats['errors'].append(error_msg)
            return self.processing_stats

    def _clean_old_chunks(self):
        """
        æ¸…ç†æ—§çš„åˆ†å—æ–‡ä»¶ï¼ˆæŒ‰æ–‡æ¡£å½’ç±»ç‰ˆï¼‰
        """
        if self.chunks_dir.exists():
            # åˆ é™¤chunksç›®å½•ä¸­çš„æ‰€æœ‰.mdæ–‡ä»¶ï¼ˆç›´æ¥åœ¨æ ¹ç›®å½•çš„æ–‡ä»¶ï¼‰
            for md_file in self.chunks_dir.glob("*.md"):
                try:
                    md_file.unlink()
                    logger.debug(f"åˆ é™¤æ—§åˆ†å—æ–‡ä»¶: {md_file.name}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {md_file.name}: {str(e)}")

            # åˆ é™¤æ‰€æœ‰å­ç›®å½•åŠå…¶å†…å®¹
            for subdir in self.chunks_dir.iterdir():
                if subdir.is_dir():
                    # åˆ é™¤å­ç›®å½•ä¸­çš„æ‰€æœ‰.mdæ–‡ä»¶
                    for md_file in subdir.glob("*.md"):
                        try:
                            md_file.unlink()
                            logger.debug(f"åˆ é™¤æ—§åˆ†å—æ–‡ä»¶: {subdir.name}/{md_file.name}")
                        except Exception as e:
                            logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {subdir.name}/{md_file.name}: {str(e)}")

                    # åˆ é™¤å­ç›®å½•ï¼ˆæ— è®ºæ˜¯å¦ä¸ºç©ºï¼‰
                    try:
                        subdir.rmdir()
                        logger.debug(f"åˆ é™¤æ–‡æ¡£ç›®å½•: {subdir.name}")
                    except Exception as e:
                        logger.warning(f"åˆ é™¤ç›®å½•å¤±è´¥ {subdir.name}: {str(e)}")

            logger.info(f"æ¸…ç†å®Œæˆ: {self.chunks_dir}")
        else:
            logger.info(f"ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†: {self.chunks_dir}")

    def _convert_documents(self) -> Dict[str, str]:
        """
        ç¬¬ä¸€é˜¶æ®µï¼šè½¬æ¢æ‰€æœ‰æ–‡æ¡£ä¸ºmarkdownæ ¼å¼

        Returns:
            è½¬æ¢ç»“æœå­—å…¸ {åŸæ–‡ä»¶è·¯å¾„: è½¬æ¢åæ–‡ä»¶è·¯å¾„}
        """
        logger.info("å¼€å§‹æ–‡æ¡£æ ¼å¼è½¬æ¢...")

        # æ‰¹é‡è½¬æ¢æ–‡æ¡£
        conversion_results = self.converter.convert_directory(str(self.input_dir))

        self.processing_stats['converted_files'] = len(conversion_results)

        if conversion_results:
            logger.info(f"æ–‡æ¡£è½¬æ¢å®Œæˆï¼Œå…±è½¬æ¢ {len(conversion_results)} ä¸ªæ–‡ä»¶")
            logger.info("è½¬æ¢ç»“æœ:")
            for original, converted in conversion_results.items():
                logger.info(f"  âœ“ {Path(original).name} -> {Path(converted).name}")
        else:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°å¯è½¬æ¢çš„æ–‡æ¡£")

        return conversion_results

    def _process_chunks(self, conversion_results: Dict[str, str]):
        """
        ç¬¬äºŒé˜¶æ®µï¼šå¤„ç†æ–‡æ¡£åˆ†å—

        Args:
            conversion_results: æ–‡æ¡£è½¬æ¢ç»“æœ
        """
        logger.info("å¼€å§‹æ–‡æ¡£åˆ†å—å¤„ç†...")

        # å¤„ç†è½¬æ¢åçš„markdownæ–‡æ¡£
        for original_file, converted_file in conversion_results.items():
            try:
                original_path = Path(original_file)
                converted_path = Path(converted_file)

                logger.info(f"å¤„ç†æ–‡æ¡£: {original_path.name}")

                # åˆ¤æ–­åŸæ–‡ä»¶ç±»å‹
                if original_path.suffix.lower() in ['.xlsx', '.xls']:
                    # Excelæ–‡ä»¶ï¼šç›´æ¥å¤„ç†åŸæ–‡ä»¶
                    self._process_excel_file(str(original_path))
                else:
                    # æ–‡æœ¬æ–‡æ¡£ï¼šå¤„ç†è½¬æ¢åçš„markdownæ–‡ä»¶
                    self._process_text_file(str(converted_path), str(original_path))

            except Exception as e:
                error_msg = f"å¤„ç†æ–‡æ¡£å¤±è´¥ {Path(original_file).name}: {str(e)}"
                logger.error(error_msg)
                self.processing_stats['errors'].append(error_msg)

    def _process_text_file(self, markdown_file: str, original_file: str):
        """
        å¤„ç†æ–‡æœ¬æ–‡æ¡£åˆ†å—ï¼ˆæŒ‰æ–‡æ¡£å½’ç±»ç‰ˆï¼‰

        Args:
            markdown_file: è½¬æ¢åçš„markdownæ–‡ä»¶è·¯å¾„
            original_file: åŸå§‹æ–‡ä»¶è·¯å¾„
        """
        try:
            original_path = Path(original_file)
            doc_name = original_path.stem  # ä¸åŒ…å«æ‰©å±•åçš„æ–‡ä»¶å

            # åœ¨chunksæ–‡ä»¶å¤¹ä¸‹ä¸ºæ¯ä¸ªæ–‡æ¡£åˆ›å»ºå­æ–‡ä»¶å¤¹
            doc_chunks_dir = self.chunks_dir / doc_name
            doc_chunks_dir.mkdir(exist_ok=True)

            # è¯»å–markdownå†…å®¹
            with open(markdown_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # æŒ‰å›ºå®šå¤§å°åˆ†å—
            chunks = self.text_chunker.chunk_by_sections(content, original_path.name)

            if chunks:
                # ä¿å­˜åˆ†å—åˆ°æ–‡æ¡£ä¸“ç”¨å­æ–‡ä»¶å¤¹
                self.text_chunker.save_chunks(chunks, str(doc_chunks_dir))
                self.processing_stats['text_chunks'] += len(chunks)

                logger.info(f"æ–‡æœ¬åˆ†å—å®Œæˆ: {original_path.name}, ç”Ÿæˆ {len(chunks)} ä¸ªåˆ†å—")
            else:
                logger.warning(f"æ–‡æ¡£æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆåˆ†å—: {original_path.name}")

        except Exception as e:
            raise Exception(f"æ–‡æœ¬åˆ†å—å¤„ç†å¤±è´¥: {str(e)}")

    def _process_excel_file(self, excel_file: str):
        """
        å¤„ç†Excelæ–‡æ¡£åˆ†å—ï¼ˆæŒ‰æ–‡æ¡£å½’ç±»ç‰ˆï¼‰

        Args:
            excel_file: Excelæ–‡ä»¶è·¯å¾„
        """
        try:
            excel_path = Path(excel_file)
            doc_name = excel_path.stem  # ä¸åŒ…å«æ‰©å±•åçš„æ–‡ä»¶å

            # åœ¨chunksæ–‡ä»¶å¤¹ä¸‹ä¸ºæ¯ä¸ªExcelæ–‡æ¡£åˆ›å»ºå­æ–‡ä»¶å¤¹
            doc_chunks_dir = self.chunks_dir / doc_name
            doc_chunks_dir.mkdir(exist_ok=True)

            # å¤„ç†Excelæ–‡ä»¶
            chunks = self.excel_chunker.process_excel_file(excel_file)

            if chunks:
                # ä¿å­˜åˆ†å—åˆ°æ–‡æ¡£ä¸“ç”¨å­æ–‡ä»¶å¤¹
                self.excel_chunker.save_chunks(chunks, str(doc_chunks_dir))
                self.processing_stats['excel_chunks'] += len(chunks)

                logger.info(f"Excelåˆ†å—å®Œæˆ: {excel_path.name}, ç”Ÿæˆ {len(chunks)} ä¸ªåˆ†å—")
            else:
                logger.warning(f"Excelæ–‡ä»¶æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆåˆ†å—: {excel_path.name}")

        except Exception as e:
            raise Exception(f"Excelåˆ†å—å¤„ç†å¤±è´¥: {str(e)}")

    def _generate_report(self):
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Šï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        report_file = self.output_base_dir / "processing_report.md"

        # ç®€åŒ–çš„æŠ¥å‘Šå†…å®¹
        report_content = f"""# æ–‡æ¡£å¤„ç†å·¥ä½œæµç¨‹æŠ¥å‘Š

## å¤„ç†ç»Ÿè®¡

- **è½¬æ¢æ–‡ä»¶æ•°**: {self.processing_stats['converted_files']}
- **æ–‡æœ¬åˆ†å—æ•°**: {self.processing_stats['text_chunks']}
- **Excelåˆ†å—æ•°**: {self.processing_stats['excel_chunks']}
- **é”™è¯¯æ•°é‡**: {len(self.processing_stats['errors'])}

## è¾“å‡ºç›®å½•

- **è½¬æ¢æ–‡ä»¶**: {self.converted_dir}
- **åˆ†å—æ–‡ä»¶**: {self.chunks_dir}

## åˆ†å—è¯´æ˜

æ‰€æœ‰æ–‡æ¡£åˆ†å—éƒ½æŒ‰æ–‡æ¡£å½’ç±»å­˜å‚¨åœ¨chunksç›®å½•ä¸‹ï¼Œæ¯ä¸ªæºæ–‡æ¡£æœ‰ç‹¬ç«‹çš„å­æ–‡ä»¶å¤¹ã€‚
åˆ†å—é‡‡ç”¨å›ºå®šå¤§å°ç­–ç•¥ï¼š5000å­—ç¬¦/å—ï¼Œ1000å­—ç¬¦é‡å ã€‚
"""

        if self.processing_stats['errors']:
            report_content += "\n## é”™è¯¯ä¿¡æ¯\n\n"
            for i, error in enumerate(self.processing_stats['errors'], 1):
                report_content += f"{i}. {error}\n"

        # ä¿å­˜æŠ¥å‘Š
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)

        logger.info(f"å¤„ç†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

        # æ‰“å°æ‘˜è¦
        logger.info("å¤„ç†æ‘˜è¦:")
        logger.info(f"  è½¬æ¢æ–‡ä»¶: {self.processing_stats['converted_files']} ä¸ª")
        logger.info(f"  æ–‡æœ¬åˆ†å—: {self.processing_stats['text_chunks']} ä¸ª")
        logger.info(f"  Excelåˆ†å—: {self.processing_stats['excel_chunks']} ä¸ª")
        if self.processing_stats['errors']:
            logger.warning(f"  é”™è¯¯: {len(self.processing_stats['errors'])} ä¸ª")

    def process_single_document(self, file_path: str) -> Dict:
        """
        å¤„ç†å•ä¸ªæ–‡æ¡£

        Args:
            file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„

        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        file_path = Path(file_path)
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†å•ä¸ªæ–‡æ¡£: {file_path.name}")

        if not file_path.exists():
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return {"status": "error", "message": "æ–‡ä»¶ä¸å­˜åœ¨"}

        try:
            # ç¡®å®šæ–‡æ¡£ç±»å‹å’Œå¤„ç†æ–¹æ³•
            if file_path.suffix.lower() in ['.xlsx', '.xls']:
                # Excelæ–‡æ¡£å¤„ç†
                result = self._process_single_excel_document(file_path)
            else:
                # å…¶ä»–æ–‡æ¡£å¤„ç†
                result = self._process_single_regular_document(file_path)

            logger.info(f"âœ… å•ä¸ªæ–‡æ¡£å¤„ç†å®Œæˆ: {file_path.name}")
            return result

        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–‡æ¡£å¤±è´¥ {file_path.name}: {e}")
            return {"status": "error", "message": str(e)}

    def _process_single_regular_document(self, file_path: Path) -> Dict:
        """å¤„ç†å•ä¸ªå¸¸è§„æ–‡æ¡£ï¼ˆéExcelï¼‰"""
        doc_name = file_path.stem

        # æ­¥éª¤1: æ–‡æ¡£è½¬æ¢
        logger.info(f"ğŸ“„ è½¬æ¢æ–‡æ¡£: {file_path.name}")
        converted_file = self.converter.convert_document(str(file_path), str(self.converted_dir))

        if not converted_file:
            raise Exception("æ–‡æ¡£è½¬æ¢å¤±è´¥")

        # æ­¥éª¤2: æ–‡æœ¬åˆ†å—
        logger.info(f"âœ‚ï¸ åˆ†å—æ–‡æ¡£: {file_path.name}")
        chunks_output_dir = self.chunks_dir / doc_name
        chunks_output_dir.mkdir(parents=True, exist_ok=True)

        chunk_files = self.text_chunker.chunk_document(
            converted_file,
            str(chunks_output_dir)
        )

        return {
            "status": "success",
            "document": doc_name,
            "converted_file": converted_file,
            "chunks_count": len(chunk_files),
            "chunks_dir": str(chunks_output_dir)
        }

    def _process_single_excel_document(self, file_path: Path) -> Dict:
        """å¤„ç†å•ä¸ªExcelæ–‡æ¡£"""
        doc_name = file_path.stem

        # Excelæ–‡æ¡£ç›´æ¥åˆ†å—
        logger.info(f"ğŸ“Š åˆ†å—Excelæ–‡æ¡£: {file_path.name}")
        chunks_output_dir = self.chunks_dir / doc_name
        chunks_output_dir.mkdir(parents=True, exist_ok=True)

        chunk_files = self.excel_chunker.chunk_excel(
            str(file_path),
            str(chunks_output_dir)
        )

        return {
            "status": "success",
            "document": doc_name,
            "chunks_count": len(chunk_files),
            "chunks_dir": str(chunks_output_dir)
        }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è‡ªåŠ¨åŒ–æ–‡æ¡£å¤„ç†å·¥ä½œæµç¨‹')
    parser.add_argument('--input', '-i', default='KnowledgeBase',
                       help='è¾“å…¥æ–‡æ¡£ç›®å½• (é»˜è®¤: KnowledgeBase)')
    parser.add_argument('--output', '-o', default='processed_documents',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: processed_documents)')
    parser.add_argument('--chunk-size', '-c', type=int, default=5000,
                       help='æ–‡æœ¬åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼Œé»˜è®¤: 5000ï¼‰')
    parser.add_argument('--overlap-size', '-ol', type=int, default=1000,
                       help='æ–‡æœ¬åˆ†å—é‡å å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼Œé»˜è®¤: 1000ï¼‰')
    parser.add_argument('--excel-chunk-size', '-ec', type=int, default=40,
                       help='Excelåˆ†å—å¤§å°ï¼ˆè¡Œæ•°ï¼Œé»˜è®¤: 40ï¼‰')

    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not Path(args.input).exists():
        logger.error(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)

    # åˆ›å»ºå·¥ä½œæµç¨‹å®ä¾‹
    workflow = DocumentProcessingWorkflow(
        input_dir=args.input,
        output_base_dir=args.output,
        chunk_size=args.chunk_size,
        overlap_size=args.overlap_size
    )

    # è®¾ç½®Excelåˆ†å—å¤§å°
    workflow.excel_chunker.chunk_size = args.excel_chunk_size

    # è¿è¡Œå·¥ä½œæµç¨‹
    results = workflow.run_full_workflow()

    # è¾“å‡ºæœ€ç»ˆç»“æœ
    print("\n" + "=" * 60)
    print("æ–‡æ¡£å¤„ç†å·¥ä½œæµç¨‹å®Œæˆ!")
    print(f"è½¬æ¢æ–‡ä»¶: {results['converted_files']} ä¸ª")
    print(f"æ–‡æœ¬åˆ†å—: {results['text_chunks']} ä¸ª")
    print(f"Excelåˆ†å—: {results['excel_chunks']} ä¸ª")
    print(f"åˆ†å—å‚æ•°: {args.chunk_size}å­—ç¬¦/å—, {args.overlap_size}å­—ç¬¦é‡å ")

    if results['errors']:
        print(f"é”™è¯¯: {len(results['errors'])} ä¸ª")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯è¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: document_processing.log")

    print(f"è¾“å‡ºç›®å½•: {workflow.output_base_dir}")
    print("=" * 60)


if __name__ == "__main__":
    main()