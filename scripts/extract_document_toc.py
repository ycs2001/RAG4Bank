#!/usr/bin/env python3
"""
æ–‡æ¡£ç›®å½•æå–è„šæœ¬
ç”¨äºæ‰¹é‡æˆ–å•ç‹¬æå–æ–‡æ¡£çš„ç›®å½•ç»“æ„
"""

import sys
import argparse
import logging
from pathlib import Path
from typing import Optional, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'src'))

from src.config import EnhancedConfigManager
from src.core.document_preprocessor import DocumentPreprocessor
from src.llm.qwen_llm import QwenLLM

def setup_logging(verbose: bool = False):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('logs/document_extraction.log')
        ]
    )

def extract_single_document(document_id: str, config_manager: EnhancedConfigManager,
                          preprocessor: DocumentPreprocessor) -> bool:
    """
    æå–å•ä¸ªæ–‡æ¡£çš„ç›®å½•
    
    Args:
        document_id: æ–‡æ¡£ID
        config_manager: é…ç½®ç®¡ç†å™¨
        preprocessor: æ–‡æ¡£é¢„å¤„ç†å™¨
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    logger = logging.getLogger(__name__)
    
    try:
        # è·å–æ–‡æ¡£é…ç½®
        toc_config = config_manager.get('documents.toc', {})
        if document_id not in toc_config:
            logger.error(f"âŒ æ–‡æ¡£IDä¸å­˜åœ¨: {document_id}")
            return False
        
        doc_info = toc_config[document_id]
        file_path = doc_info.get('file_path')
        
        if not file_path:
            logger.error(f"âŒ æ–‡æ¡£ {document_id} ç¼ºå°‘file_pathé…ç½®")
            return False
        
        if not Path(file_path).exists():
            logger.error(f"âŒ æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False
        
        logger.info(f"ğŸ” å¼€å§‹æå–æ–‡æ¡£ç›®å½•: {document_id}")
        logger.info(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {file_path}")
        
        # æ‰§è¡Œç›®å½•æå–
        result = preprocessor.extract_document_toc(document_id, file_path)
        
        if result.get('status') == 'completed':
            chapters_count = len(result.get('chapters', []))
            confidence = result.get('confidence', 0.0)
            logger.info(f"âœ… ç›®å½•æå–æˆåŠŸ: {document_id}")
            logger.info(f"ğŸ“‹ æå–åˆ° {chapters_count} ä¸ªç« èŠ‚")
            logger.info(f"ğŸ¯ ç½®ä¿¡åº¦: {confidence:.2f}")
            return True
        else:
            logger.error(f"âŒ ç›®å½•æå–å¤±è´¥: {document_id}")
            logger.error(f"é”™è¯¯ä¿¡æ¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å¤„ç†æ–‡æ¡£ {document_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return False

def extract_all_documents(config_manager: EnhancedConfigManager,
                         preprocessor: DocumentPreprocessor,
                         force: bool = False) -> dict:
    """
    æ‰¹é‡æå–æ‰€æœ‰æ–‡æ¡£çš„ç›®å½•
    
    Args:
        config_manager: é…ç½®ç®¡ç†å™¨
        preprocessor: æ–‡æ¡£é¢„å¤„ç†å™¨
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°æå–å·²å®Œæˆçš„æ–‡æ¡£
        
    Returns:
        å¤„ç†ç»“æœç»Ÿè®¡
    """
    logger = logging.getLogger(__name__)
    
    toc_config = config_manager.get('documents.toc', {})
    if not toc_config:
        logger.warning("âš ï¸ æ²¡æœ‰é…ç½®ä»»ä½•æ–‡æ¡£")
        return {'total': 0, 'success': 0, 'failed': 0, 'skipped': 0}
    
    results = {
        'total': len(toc_config),
        'success': 0,
        'failed': 0,
        'skipped': 0,
        'details': {}
    }
    
    logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {results['total']} ä¸ªæ–‡æ¡£")
    
    for i, (document_id, doc_info) in enumerate(toc_config.items(), 1):
        logger.info(f"\nğŸ“„ å¤„ç†æ–‡æ¡£ {i}/{results['total']}: {document_id}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡
        extraction_status = doc_info.get('extraction_status', 'pending')
        if extraction_status == 'completed' and not force:
            logger.info(f"â­ï¸ è·³è¿‡å·²å®Œæˆçš„æ–‡æ¡£: {document_id}")
            results['skipped'] += 1
            results['details'][document_id] = 'skipped'
            continue
        
        # æ‰§è¡Œæå–
        success = extract_single_document(document_id, config_manager, preprocessor)
        
        if success:
            results['success'] += 1
            results['details'][document_id] = 'success'
        else:
            results['failed'] += 1
            results['details'][document_id] = 'failed'
        
        # æ˜¾ç¤ºè¿›åº¦
        progress = (i / results['total']) * 100
        logger.info(f"ğŸ“Š è¿›åº¦: {progress:.1f}% ({i}/{results['total']})")
    
    return results

def print_summary(results: dict):
    """æ‰“å°å¤„ç†ç»“æœæ‘˜è¦"""
    logger = logging.getLogger(__name__)
    
    logger.info("\n" + "="*50)
    logger.info("ğŸ“Š å¤„ç†ç»“æœæ‘˜è¦")
    logger.info("="*50)
    logger.info(f"æ€»æ–‡æ¡£æ•°: {results['total']}")
    logger.info(f"æˆåŠŸ: {results['success']}")
    logger.info(f"å¤±è´¥: {results['failed']}")
    logger.info(f"è·³è¿‡: {results['skipped']}")
    
    if results.get('details'):
        logger.info("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for doc_id, status in results['details'].items():
            status_icon = {
                'success': 'âœ…',
                'failed': 'âŒ', 
                'skipped': 'â­ï¸'
            }.get(status, 'â“')
            logger.info(f"  {status_icon} {doc_id}: {status}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ–‡æ¡£ç›®å½•æå–å·¥å…·')
    parser.add_argument('--document', '-d', type=str, help='æŒ‡å®šè¦å¤„ç†çš„æ–‡æ¡£ID')
    parser.add_argument('--all', '-a', action='store_true', help='å¤„ç†æ‰€æœ‰æ–‡æ¡£')
    parser.add_argument('--force', '-f', action='store_true', help='å¼ºåˆ¶é‡æ–°å¤„ç†å·²å®Œæˆçš„æ–‡æ¡£')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†æ—¥å¿—è¾“å‡º')
    parser.add_argument('--list', '-l', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ–‡æ¡£ID')
    parser.add_argument('--pipeline', '-p', action='store_true', help='è¿è¡Œè‡ªåŠ¨åŒ–Pipelineï¼ˆæ¨èï¼‰')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.verbose)
    logger = logging.getLogger(__name__)
    
    try:
        # Pipelineæ¨¡å¼
        if args.pipeline:
            logger.info("ğŸš€ å¯åŠ¨è‡ªåŠ¨åŒ–Pipelineæ¨¡å¼...")
            import sys
            from pathlib import Path

            # æ·»åŠ è„šæœ¬ç›®å½•åˆ°è·¯å¾„
            script_dir = Path(__file__).parent
            sys.path.insert(0, str(script_dir))

            from toc_extraction_pipeline import TOCExtractionPipeline

            pipeline = TOCExtractionPipeline()
            target_docs = [args.document] if args.document else None

            success = pipeline.run_full_pipeline(
                target_docs=target_docs if not args.all else None,
                test_semantic=True
            )

            if success:
                logger.info("ğŸ‰ Pipelineæ‰§è¡ŒæˆåŠŸï¼")
            else:
                logger.error("ğŸ’¥ Pipelineæ‰§è¡Œå¤±è´¥ï¼")
                sys.exit(1)
            return

        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        logger.info("ğŸ”§ åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨...")
        config_manager = EnhancedConfigManager()

        # åˆ—å‡ºæ–‡æ¡£ID
        if args.list:
            toc_config = config_manager.get('documents.toc', {})
            logger.info("ğŸ“‹ å¯ç”¨çš„æ–‡æ¡£ID:")
            for doc_id, doc_info in toc_config.items():
                status = doc_info.get('extraction_status', 'pending')
                title = doc_info.get('title', 'æœªçŸ¥æ ‡é¢˜')
                logger.info(f"  â€¢ {doc_id}: {title} (çŠ¶æ€: {status})")
            return
        
        # åˆå§‹åŒ–LLM
        logger.info("ğŸ¤– åˆå§‹åŒ–LLM...")
        default_provider = config_manager.get('llm.default_provider', 'deepseek')

        if default_provider == 'deepseek':
            from src.llm.deepseek_llm import DeepSeekLLM
            deepseek_config = config_manager.get('llm.deepseek', {})
            llm = DeepSeekLLM(deepseek_config)
        else:
            # é»˜è®¤ä½¿ç”¨Qwen
            qwen_config = config_manager.get('llm.qwen', {})
            llm = QwenLLM(qwen_config)
        
        # åˆå§‹åŒ–æ–‡æ¡£é¢„å¤„ç†å™¨
        logger.info("ğŸ“„ åˆå§‹åŒ–æ–‡æ¡£é¢„å¤„ç†å™¨...")
        preprocessor = DocumentPreprocessor(config_manager, llm)
        
        if not preprocessor.enabled:
            logger.error("âŒ æ–‡æ¡£é¢„å¤„ç†å™¨æœªå¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®")
            return
        
        # æ‰§è¡Œå¤„ç†
        if args.document:
            # å¤„ç†å•ä¸ªæ–‡æ¡£
            success = extract_single_document(args.document, config_manager, preprocessor)
            if success:
                logger.info("ğŸ‰ æ–‡æ¡£å¤„ç†å®Œæˆ")
            else:
                logger.error("ğŸ’¥ æ–‡æ¡£å¤„ç†å¤±è´¥")
                sys.exit(1)
                
        elif args.all:
            # æ‰¹é‡å¤„ç†
            results = extract_all_documents(config_manager, preprocessor, args.force)
            print_summary(results)
            
            if results['failed'] > 0:
                logger.warning(f"âš ï¸ æœ‰ {results['failed']} ä¸ªæ–‡æ¡£å¤„ç†å¤±è´¥")
                sys.exit(1)
            else:
                logger.info("ğŸ‰ æ‰€æœ‰æ–‡æ¡£å¤„ç†å®Œæˆ")
        else:
            parser.print_help()
            
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()
