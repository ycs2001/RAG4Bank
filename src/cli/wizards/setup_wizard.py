"""
ç³»ç»Ÿè®¾ç½®å‘å¯¼
"""

import os
from pathlib import Path
from typing import Dict, Any, Optional

class SetupWizard:
    """ç³»ç»Ÿè®¾ç½®å‘å¯¼"""
    
    def __init__(self):
        """åˆå§‹åŒ–å‘å¯¼"""
        self.config = {}
    
    def run(self) -> Dict[str, Any]:
        """è¿è¡Œè®¾ç½®å‘å¯¼"""
        print("ğŸ§™â€â™‚ï¸ CategoryRAG è®¾ç½®å‘å¯¼")
        print("=" * 50)
        print("æˆ‘å°†å¼•å¯¼æ‚¨å®ŒæˆCategoryRAGçš„åˆå§‹é…ç½®\n")
        
        # æ­¥éª¤1: åŸºæœ¬é…ç½®
        self._step_basic_config()
        
        # æ­¥éª¤2: æ¨¡å‹é…ç½®
        self._step_model_config()
        
        # æ­¥éª¤3: LLMé…ç½®
        self._step_llm_config()
        
        # æ­¥éª¤4: æœåŠ¡é…ç½®
        self._step_service_config()
        
        # æ­¥éª¤5: ç¡®è®¤é…ç½®
        self._step_confirm_config()
        
        return self.config
    
    def _step_basic_config(self):
        """åŸºæœ¬é…ç½®æ­¥éª¤"""
        print("ğŸ“‹ æ­¥éª¤ 1/5: åŸºæœ¬é…ç½®")
        print("-" * 30)
        
        # ç³»ç»Ÿåç§°
        system_name = self._get_input(
            "ç³»ç»Ÿåç§°", 
            "CategoryRAG",
            "ç”¨äºæ ‡è¯†æ‚¨çš„CategoryRAGå®ä¾‹"
        )
        
        # ç¯å¢ƒ
        environment = self._get_choice(
            "è¿è¡Œç¯å¢ƒ",
            ["development", "production", "testing"],
            "development",
            "é€‰æ‹©ç³»ç»Ÿè¿è¡Œç¯å¢ƒ"
        )
        
        # æ•°æ®ç›®å½•
        data_dir = self._get_input(
            "æ•°æ®ç›®å½•",
            "data",
            "å­˜å‚¨æ–‡æ¡£å’Œæ•°æ®åº“çš„æ ¹ç›®å½•"
        )
        
        self.config.update({
            "system": {
                "name": system_name,
                "environment": environment
            },
            "data_dir": data_dir
        })
        
        print("âœ… åŸºæœ¬é…ç½®å®Œæˆ\n")
    
    def _step_model_config(self):
        """æ¨¡å‹é…ç½®æ­¥éª¤"""
        print("ğŸ“‹ æ­¥éª¤ 2/5: æ¨¡å‹é…ç½®")
        print("-" * 30)
        
        # BGEæ¨¡å‹è·¯å¾„
        print("ğŸ¤– é…ç½®BGEåµŒå…¥æ¨¡å‹:")
        print("BGEæ¨¡å‹ç”¨äºå°†æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡ï¼Œæ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶")
        
        while True:
            bge_path = self._get_input(
                "BGEæ¨¡å‹è·¯å¾„",
                "/Users/chongshenyang/Desktop/bge-large-zh-v1.5",
                "BGEæ¨¡å‹çš„æœ¬åœ°è·¯å¾„"
            )
            
            if not bge_path:
                if self._confirm("è·³è¿‡BGEæ¨¡å‹é…ç½®ï¼ˆç¨åå¯æ‰‹åŠ¨é…ç½®ï¼‰"):
                    break
                continue
            
            if Path(bge_path).exists():
                print("âœ… BGEæ¨¡å‹è·¯å¾„éªŒè¯æˆåŠŸ")
                break
            else:
                print("âŒ è·¯å¾„ä¸å­˜åœ¨")
                if not self._confirm("é‡æ–°è¾“å…¥è·¯å¾„"):
                    bge_path = ""
                    break
        
        # é‡æ’æ¨¡å‹é…ç½®
        use_reranker = self._confirm(
            "å¯ç”¨Cross-Encoderé‡æ’æ¨¡å‹",
            True,
            "é‡æ’æ¨¡å‹å¯ä»¥æé«˜æ£€ç´¢ç²¾åº¦ï¼Œä½†ä¼šå¢åŠ è®¡ç®—æ—¶é—´"
        )
        
        self.config.update({
            "embedding": {
                "model": {
                    "path": bge_path
                }
            },
            "reranker": {
                "enabled": use_reranker
            }
        })
        
        print("âœ… æ¨¡å‹é…ç½®å®Œæˆ\n")
    
    def _step_llm_config(self):
        """LLMé…ç½®æ­¥éª¤"""
        print("ğŸ“‹ æ­¥éª¤ 3/5: LLMé…ç½®")
        print("-" * 30)
        
        print("ğŸ”— é…ç½®å¤§è¯­è¨€æ¨¡å‹:")
        print("LLMç”¨äºç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œéœ€è¦APIå¯†é’¥")
        
        # é€‰æ‹©ä¸»è¦LLMæä¾›å•†
        llm_provider = self._get_choice(
            "ä¸»è¦LLMæä¾›å•†",
            ["deepseek", "qwen", "openai"],
            "deepseek",
            "é€‰æ‹©æ‚¨çš„ä¸»è¦LLMæœåŠ¡æä¾›å•†"
        )
        
        # æ£€æŸ¥APIå¯†é’¥
        api_key_env_map = {
            "deepseek": "DEEPSEEK_API_KEY",
            "qwen": "QWEN_API_KEY", 
            "openai": "OPENAI_API_KEY"
        }
        
        env_var = api_key_env_map[llm_provider]
        api_key = os.getenv(env_var)
        
        if api_key:
            print(f"âœ… æ£€æµ‹åˆ° {env_var} ç¯å¢ƒå˜é‡")
        else:
            print(f"âš ï¸ æœªæ£€æµ‹åˆ° {env_var} ç¯å¢ƒå˜é‡")
            print(f"ğŸ’¡ è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export {env_var}=your_api_key")
        
        # é…ç½®å¤‡ç”¨LLM
        use_fallback = self._confirm(
            "é…ç½®å¤‡ç”¨LLM",
            False,
            "å¤‡ç”¨LLMåœ¨ä¸»è¦LLMä¸å¯ç”¨æ—¶ä½¿ç”¨"
        )
        
        fallback_provider = None
        if use_fallback:
            available_providers = [p for p in ["deepseek", "qwen", "openai"] if p != llm_provider]
            fallback_provider = self._get_choice(
                "å¤‡ç”¨LLMæä¾›å•†",
                available_providers,
                available_providers[0],
                "é€‰æ‹©å¤‡ç”¨LLMæä¾›å•†"
            )
        
        self.config.update({
            "llm": {
                "primary": {
                    "provider": llm_provider
                },
                "fallback": {
                    "provider": fallback_provider
                } if fallback_provider else None
            }
        })
        
        print("âœ… LLMé…ç½®å®Œæˆ\n")
    
    def _step_service_config(self):
        """æœåŠ¡é…ç½®æ­¥éª¤"""
        print("ğŸ“‹ æ­¥éª¤ 4/5: æœåŠ¡é…ç½®")
        print("-" * 30)
        
        # GROBIDæœåŠ¡é…ç½®
        print("ğŸ”§ é…ç½®GROBIDæœåŠ¡:")
        print("GROBIDç”¨äºè§£æPDFæ–‡æ¡£ç»“æ„ï¼Œæé«˜æ–‡æ¡£å¤„ç†è´¨é‡")
        
        use_grobid = self._confirm(
            "å¯ç”¨GROBIDæœåŠ¡",
            True,
            "å»ºè®®å¯ç”¨ä»¥è·å¾—æ›´å¥½çš„PDFå¤„ç†æ•ˆæœ"
        )
        
        grobid_url = "http://localhost:8070"
        if use_grobid:
            grobid_url = self._get_input(
                "GROBIDæœåŠ¡URL",
                "http://localhost:8070",
                "GROBIDæœåŠ¡çš„è®¿é—®åœ°å€"
            )
        
        # æ€§èƒ½é…ç½®
        print("\nâš¡ æ€§èƒ½é…ç½®:")
        max_workers = self._get_number_input(
            "æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°",
            4,
            1, 16,
            "å¹¶è¡Œå¤„ç†çš„çº¿ç¨‹æ•°ï¼Œå»ºè®®è®¾ç½®ä¸ºCPUæ ¸å¿ƒæ•°"
        )
        
        self.config.update({
            "services": {
                "grobid": {
                    "enabled": use_grobid,
                    "url": grobid_url
                }
            },
            "performance": {
                "max_workers": max_workers
            }
        })
        
        print("âœ… æœåŠ¡é…ç½®å®Œæˆ\n")
    
    def _step_confirm_config(self):
        """ç¡®è®¤é…ç½®æ­¥éª¤"""
        print("ğŸ“‹ æ­¥éª¤ 5/5: ç¡®è®¤é…ç½®")
        print("-" * 30)
        
        print("ğŸ“‹ é…ç½®æ‘˜è¦:")
        print(f"   ç³»ç»Ÿåç§°: {self.config['system']['name']}")
        print(f"   è¿è¡Œç¯å¢ƒ: {self.config['system']['environment']}")
        print(f"   æ•°æ®ç›®å½•: {self.config['data_dir']}")
        print(f"   BGEæ¨¡å‹: {self.config['embedding']['model']['path'] or 'æœªé…ç½®'}")
        print(f"   é‡æ’æ¨¡å‹: {'å¯ç”¨' if self.config['reranker']['enabled'] else 'ç¦ç”¨'}")
        print(f"   ä¸»è¦LLM: {self.config['llm']['primary']['provider']}")
        print(f"   GROBID: {'å¯ç”¨' if self.config['services']['grobid']['enabled'] else 'ç¦ç”¨'}")
        print(f"   å·¥ä½œçº¿ç¨‹: {self.config['performance']['max_workers']}")
        
        if not self._confirm("ç¡®è®¤ä»¥ä¸Šé…ç½®", True):
            print("âš ï¸ é…ç½®å·²å–æ¶ˆ")
            return False
        
        print("âœ… é…ç½®ç¡®è®¤å®Œæˆ\n")
        return True
    
    def _get_input(self, prompt: str, default: str = "", description: str = "") -> str:
        """è·å–ç”¨æˆ·è¾“å…¥"""
        if description:
            print(f"ğŸ’¡ {description}")
        
        if default:
            full_prompt = f"ğŸ“ {prompt} [{default}]: "
        else:
            full_prompt = f"ğŸ“ {prompt}: "
        
        response = input(full_prompt).strip()
        return response if response else default
    
    def _get_choice(self, prompt: str, choices: list, default: str, description: str = "") -> str:
        """è·å–ç”¨æˆ·é€‰æ‹©"""
        if description:
            print(f"ğŸ’¡ {description}")
        
        print(f"ğŸ“ {prompt}:")
        for i, choice in enumerate(choices, 1):
            marker = " (é»˜è®¤)" if choice == default else ""
            print(f"   {i}. {choice}{marker}")
        
        while True:
            response = input("è¯·é€‰æ‹© [1-{}]: ".format(len(choices))).strip()
            
            if not response:
                return default
            
            try:
                index = int(response) - 1
                if 0 <= index < len(choices):
                    return choices[index]
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æ•°å­—")
    
    def _get_number_input(self, prompt: str, default: int, min_val: int, max_val: int, description: str = "") -> int:
        """è·å–æ•°å­—è¾“å…¥"""
        if description:
            print(f"ğŸ’¡ {description}")
        
        while True:
            response = input(f"ğŸ“ {prompt} [{default}] ({min_val}-{max_val}): ").strip()
            
            if not response:
                return default
            
            try:
                value = int(response)
                if min_val <= value <= max_val:
                    return value
                else:
                    print(f"âŒ æ•°å€¼å¿…é¡»åœ¨ {min_val}-{max_val} ä¹‹é—´")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
    
    def _confirm(self, prompt: str, default: bool = False, description: str = "") -> bool:
        """ç¡®è®¤å¯¹è¯æ¡†"""
        if description:
            print(f"ğŸ’¡ {description}")
        
        suffix = " [Y/n]" if default else " [y/N]"
        response = input(f"â“ {prompt}{suffix}: ").strip().lower()
        
        if not response:
            return default
        
        return response in ['y', 'yes', 'æ˜¯', 'true', '1']
