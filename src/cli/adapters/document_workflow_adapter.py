"""
æ–‡æ¡£å·¥ä½œæµé€‚é…å™¨
ç”¨äºå°†æ–°çš„CLIç³»ç»Ÿä¸ç°æœ‰çš„æ–‡æ¡£å¤„ç†å·¥ä½œæµé›†æˆ
"""

import sys
import time
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass

@dataclass
class DocumentAddResult:
    """æ–‡æ¡£æ·»åŠ ç»“æœ"""
    status: str  # success, error
    doc_name: str
    collection_id: str
    chunks_count: int
    processing_time: float
    error_message: Optional[str] = None

class DocumentWorkflowAdapter:
    """æ–‡æ¡£å·¥ä½œæµé€‚é…å™¨"""
    
    def __init__(self, config_manager):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨
        """
        self.config_manager = config_manager
    
    def add_document(self, file_path: str, collection_config: Dict[str, Any]) -> DocumentAddResult:
        """
        æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            collection_config: é›†åˆé…ç½®
            
        Returns:
            æ–‡æ¡£æ·»åŠ ç»“æœ
        """
        start_time = time.time()
        
        try:
            # éªŒè¯æ–‡ä»¶
            file_path_obj = Path(file_path)
            if not file_path_obj.exists():
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
            supported_formats = self.config_manager.get_supported_formats()
            if file_path_obj.suffix.lower() not in supported_formats:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path_obj.suffix}")
            
            # å‡†å¤‡é…ç½®
            collection_name = collection_config.get("collection_name", file_path_obj.stem)
            collection_id = collection_config.get("collection_id", self._generate_collection_id(collection_name))
            keywords = collection_config.get("keywords", [file_path_obj.stem])
            description = collection_config.get("description", f"{file_path_obj.stem}ç›¸å…³æ–‡æ¡£")
            
            # è°ƒç”¨çœŸå®çš„æ–‡æ¡£å¤„ç†å·¥ä½œæµ
            result = self._call_real_workflow(
                file_path=file_path,
                collection_id=collection_id,
                collection_name=collection_name,
                keywords=keywords,
                description=description
            )

            # ğŸ”„ è‡ªåŠ¨æ›´æ–°åŠ¨æ€é…ç½®
            try:
                from ...config.dynamic_config_manager import DynamicConfigManager

                dynamic_manager = DynamicConfigManager()
                dynamic_collection_config = {
                    'collection_name': collection_name,
                    'collection_id': collection_id,
                    'description': description,
                    'keywords': keywords,
                    'priority': 1,
                    'type': 'document'
                }

                # è‡ªåŠ¨æ›´æ–°é…ç½®
                dynamic_manager.auto_update_on_document_add(file_path, dynamic_collection_config)

            except Exception as e:
                # åŠ¨æ€é…ç½®æ›´æ–°å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                import logging
                logger = logging.getLogger(__name__)
                logger.warning(f"âš ï¸ åŠ¨æ€é…ç½®æ›´æ–°å¤±è´¥: {e}")

            processing_time = time.time() - start_time

            return DocumentAddResult(
                status="success",
                doc_name=file_path_obj.name,
                collection_id=collection_id,
                chunks_count=result["chunks_count"],
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            return DocumentAddResult(
                status="error",
                doc_name=Path(file_path).name,
                collection_id="",
                chunks_count=0,
                processing_time=processing_time,
                error_message=str(e)
            )
    
    def _generate_collection_id(self, collection_name: str) -> str:
        """ç”Ÿæˆé›†åˆID"""
        # ç®€å•çš„IDç”Ÿæˆé€»è¾‘
        import re
        collection_id = re.sub(r'[^a-zA-Z0-9_]', '_', collection_name.lower())
        collection_id = re.sub(r'_+', '_', collection_id).strip('_')
        return collection_id or "default_collection"
    
    def _process_document_mock(self, **kwargs) -> Dict[str, Any]:
        """
        æ¨¡æ‹Ÿæ–‡æ¡£å¤„ç†ï¼ˆä¸´æ—¶å®ç°ï¼‰
        å®é™…åº”è¯¥è°ƒç”¨çœŸå®çš„æ–‡æ¡£å¤„ç†å·¥ä½œæµ
        """
        file_path = kwargs["file_path"]
        file_path_obj = Path(file_path)
        
        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        import time
        time.sleep(0.5)
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹ä¼°ç®—åˆ†å—æ•°
        if file_path_obj.suffix.lower() in ['.xlsx', '.xls']:
            # Excelæ–‡ä»¶ä¼°ç®—
            try:
                import pandas as pd
                df = pd.read_excel(file_path)
                rows = len(df)
                chunks_count = max(1, rows // 40)  # å‡è®¾æ¯40è¡Œä¸€ä¸ªåˆ†å—
            except:
                chunks_count = 1
        else:
            # å…¶ä»–æ–‡ä»¶ç±»å‹ä¼°ç®—
            try:
                file_size = file_path_obj.stat().st_size
                chunks_count = max(1, file_size // 2000)  # å‡è®¾æ¯2KBä¸€ä¸ªåˆ†å—
            except:
                chunks_count = 1
        
        return {
            "chunks_count": chunks_count,
            "status": "success"
        }
    
    def _call_real_workflow(self, **kwargs) -> Dict[str, Any]:
        """
        è°ƒç”¨çœŸå®çš„æ–‡æ¡£å¤„ç†å·¥ä½œæµ
        è¿™ä¸ªæ–¹æ³•åº”è¯¥æ›¿æ¢_process_document_mock
        """
        try:
            # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
            project_root = Path(__file__).parent.parent.parent.parent
            sys.path.insert(0, str(project_root))
            
            # å¯¼å…¥çœŸå®çš„å·¥ä½œæµ
            from scripts.add_document_workflow import DocumentAddWorkflow
            
            # åˆ›å»ºå·¥ä½œæµå®ä¾‹
            workflow = DocumentAddWorkflow()
            
            # æ„å»ºå‚æ•°
            collection_config = {
                "collection_name": kwargs["collection_name"],
                "description": kwargs["description"],
                "keywords": kwargs["keywords"]
            }
            
            if "collection_id" in kwargs:
                collection_config["collection_id"] = kwargs["collection_id"]
            
            # æ‰§è¡Œå·¥ä½œæµ
            result = workflow.add_document(kwargs["file_path"], collection_config)
            
            return {
                "chunks_count": result.chunks_count if hasattr(result, 'chunks_count') else 0,
                "status": result.status if hasattr(result, 'status') else "success"
            }
            
        except Exception as e:
            raise Exception(f"æ–‡æ¡£å¤„ç†å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
    
    def validate_document(self, file_path: str) -> Dict[str, Any]:
        """
        éªŒè¯æ–‡æ¡£
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            
        Returns:
            éªŒè¯ç»“æœ
        """
        file_path_obj = Path(file_path)
        
        result = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "info": {}
        }
        
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
        if not file_path_obj.exists():
            result["valid"] = False
            result["errors"].append(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return result
        
        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        supported_formats = self.config_manager.get_supported_formats()
        if file_path_obj.suffix.lower() not in supported_formats:
            result["valid"] = False
            result["errors"].append(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path_obj.suffix}")
            result["info"]["supported_formats"] = supported_formats
            return result
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = file_path_obj.stat().st_size
        if file_size == 0:
            result["valid"] = False
            result["errors"].append("æ–‡ä»¶ä¸ºç©º")
        elif file_size > 100 * 1024 * 1024:  # 100MB
            result["warnings"].append("æ–‡ä»¶è¾ƒå¤§ï¼Œå¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
        
        # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
        result["info"].update({
            "file_name": file_path_obj.name,
            "file_size": file_size,
            "file_extension": file_path_obj.suffix,
            "estimated_chunks": self._estimate_chunks(file_path_obj)
        })
        
        return result
    
    def _estimate_chunks(self, file_path: Path) -> int:
        """ä¼°ç®—åˆ†å—æ•°é‡"""
        try:
            if file_path.suffix.lower() in ['.xlsx', '.xls']:
                import pandas as pd
                df = pd.read_excel(file_path)
                return max(1, len(df) // 40)
            else:
                file_size = file_path.stat().st_size
                return max(1, file_size // 2000)
        except:
            return 1
