"""
é…ç½®æ–‡ä»¶éªŒè¯å’Œè¿ç§»å·¥å…·
"""

import os
import yaml
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)

class ConfigValidator:
    """é…ç½®æ–‡ä»¶éªŒè¯å™¨"""
    
    def __init__(self, config_dir: str = "config"):
        self.config_dir = Path(config_dir)
        self.schema = self._load_schema()
    
    def _load_schema(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶æ¨¡å¼"""
        return {
            "required_sections": [
                "system", "data", "document_processing", 
                "embedding", "retrieval", "llm"
            ],
            "required_fields": {
                "system": ["name", "version", "environment"],
                "data": ["raw_docs_dir", "processed_docs_dir", "chroma_db_dir"],
                "embedding.model": ["name", "path"],
                "llm.primary": ["provider", "model"]
            },
            "field_types": {
                "system.version": str,
                "retrieval.top_k": int,
                "retrieval.similarity_threshold": float,
                "embedding.model.batch_size": int
            },
            "field_ranges": {
                "retrieval.top_k": (1, 1000),
                "retrieval.similarity_threshold": (0.0, 1.0),
                "embedding.model.batch_size": (1, 256)
            }
        }
    
    def validate_config(self, config_file: str) -> Dict[str, Any]:
        """
        éªŒè¯é…ç½®æ–‡ä»¶
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            éªŒè¯ç»“æœ
        """
        result = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "suggestions": [],
            "metadata": {}
        }
        
        try:
            # åŠ è½½é…ç½®æ–‡ä»¶
            config_path = self.config_dir / config_file
            if not config_path.exists():
                result["valid"] = False
                result["errors"].append(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
                return result
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            if not config:
                result["valid"] = False
                result["errors"].append("é…ç½®æ–‡ä»¶ä¸ºç©º")
                return result
            
            # éªŒè¯å¿…éœ€ç« èŠ‚
            self._validate_required_sections(config, result)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            self._validate_required_fields(config, result)
            
            # éªŒè¯å­—æ®µç±»å‹
            self._validate_field_types(config, result)
            
            # éªŒè¯å­—æ®µèŒƒå›´
            self._validate_field_ranges(config, result)
            
            # éªŒè¯è·¯å¾„å­˜åœ¨æ€§
            self._validate_paths(config, result)
            
            # éªŒè¯ç¯å¢ƒå˜é‡
            self._validate_environment_variables(config, result)
            
            # ç”Ÿæˆå»ºè®®
            self._generate_suggestions(config, result)
            
            # æ”¶é›†å…ƒæ•°æ®
            result["metadata"] = self._collect_metadata(config)
            
        except yaml.YAMLError as e:
            result["valid"] = False
            result["errors"].append(f"YAMLæ ¼å¼é”™è¯¯: {e}")
        except Exception as e:
            result["valid"] = False
            result["errors"].append(f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
        
        return result
    
    def _validate_required_sections(self, config: Dict[str, Any], result: Dict[str, Any]):
        """éªŒè¯å¿…éœ€ç« èŠ‚"""
        for section in self.schema["required_sections"]:
            if section not in config:
                result["errors"].append(f"ç¼ºå°‘å¿…éœ€ç« èŠ‚: {section}")
                result["valid"] = False
    
    def _validate_required_fields(self, config: Dict[str, Any], result: Dict[str, Any]):
        """éªŒè¯å¿…éœ€å­—æ®µ"""
        for section, fields in self.schema["required_fields"].items():
            section_parts = section.split('.')
            current = config
            
            # å¯¼èˆªåˆ°æŒ‡å®šç« èŠ‚
            for part in section_parts:
                if part not in current:
                    result["errors"].append(f"ç¼ºå°‘ç« èŠ‚: {section}")
                    result["valid"] = False
                    break
                current = current[part]
            else:
                # éªŒè¯å­—æ®µ
                for field in fields:
                    if field not in current:
                        result["errors"].append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {section}.{field}")
                        result["valid"] = False
    
    def _validate_field_types(self, config: Dict[str, Any], result: Dict[str, Any]):
        """éªŒè¯å­—æ®µç±»å‹"""
        for field_path, expected_type in self.schema["field_types"].items():
            value = self._get_nested_value(config, field_path)
            if value is not None and not isinstance(value, expected_type):
                result["warnings"].append(
                    f"å­—æ®µç±»å‹ä¸åŒ¹é…: {field_path} æœŸæœ› {expected_type.__name__}, å®é™… {type(value).__name__}"
                )
    
    def _validate_field_ranges(self, config: Dict[str, Any], result: Dict[str, Any]):
        """éªŒè¯å­—æ®µèŒƒå›´"""
        for field_path, (min_val, max_val) in self.schema["field_ranges"].items():
            value = self._get_nested_value(config, field_path)
            if value is not None:
                if not (min_val <= value <= max_val):
                    result["warnings"].append(
                        f"å­—æ®µå€¼è¶…å‡ºèŒƒå›´: {field_path} = {value}, æœ‰æ•ˆèŒƒå›´ [{min_val}, {max_val}]"
                    )
    
    def _validate_paths(self, config: Dict[str, Any], result: Dict[str, Any]):
        """éªŒè¯è·¯å¾„å­˜åœ¨æ€§"""
        path_fields = [
            "data.raw_docs_dir",
            "data.processed_docs_dir", 
            "data.chroma_db_dir",
            "embedding.model.path"
        ]
        
        for field_path in path_fields:
            path_value = self._get_nested_value(config, field_path)
            if path_value:
                path_obj = Path(path_value)
                if not path_obj.exists():
                    if "model.path" in field_path:
                        result["errors"].append(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {path_value}")
                        result["valid"] = False
                    else:
                        result["warnings"].append(f"è·¯å¾„ä¸å­˜åœ¨: {path_value}")
    
    def _validate_environment_variables(self, config: Dict[str, Any], result: Dict[str, Any]):
        """éªŒè¯ç¯å¢ƒå˜é‡"""
        env_var_fields = [
            "llm.primary.api_key",
            "llm.fallback.api_key"
        ]
        
        for field_path in env_var_fields:
            value = self._get_nested_value(config, field_path)
            if value and value.startswith("${") and value.endswith("}"):
                env_var = value[2:-1]
                if not os.getenv(env_var):
                    result["warnings"].append(f"ç¯å¢ƒå˜é‡æœªè®¾ç½®: {env_var}")
    
    def _generate_suggestions(self, config: Dict[str, Any], result: Dict[str, Any]):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        # æ€§èƒ½ä¼˜åŒ–å»ºè®®
        top_k = self._get_nested_value(config, "retrieval.top_k")
        if top_k and top_k > 100:
            result["suggestions"].append("å»ºè®®å°† retrieval.top_k è®¾ç½®ä¸º 50-100 ä»¥æé«˜æ€§èƒ½")
        
        # å®‰å…¨å»ºè®®
        debug = self._get_nested_value(config, "system.debug")
        environment = self._get_nested_value(config, "system.environment")
        if debug and environment == "production":
            result["suggestions"].append("ç”Ÿäº§ç¯å¢ƒå»ºè®®å…³é—­ debug æ¨¡å¼")
    
    def _collect_metadata(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """æ”¶é›†é…ç½®å…ƒæ•°æ®"""
        return {
            "config_version": self._get_nested_value(config, "config_metadata.version"),
            "system_version": self._get_nested_value(config, "system.version"),
            "environment": self._get_nested_value(config, "system.environment"),
            "sections_count": len(config),
            "has_dynamic_config": "dynamic_documents" in config,
            "has_prompt_config": "prompts" in config,
            "has_version_mapping": "version_mapping" in config
        }
    
    def _get_nested_value(self, data: Dict[str, Any], path: str) -> Any:
        """è·å–åµŒå¥—å­—å…¸çš„å€¼"""
        keys = path.split('.')
        current = data
        
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None
        
        return current

class ConfigMigrator:
    """é…ç½®æ–‡ä»¶è¿ç§»å·¥å…·"""
    
    def __init__(self, config_dir: str = "config"):
        self.config_dir = Path(config_dir)
    
    def migrate_to_v2(self, source_file: str = "unified_config.yaml", 
                     target_file: str = "unified_config_v2.yaml") -> bool:
        """
        è¿ç§»é…ç½®æ–‡ä»¶åˆ°v2ç‰ˆæœ¬
        
        Args:
            source_file: æºé…ç½®æ–‡ä»¶
            target_file: ç›®æ ‡é…ç½®æ–‡ä»¶
            
        Returns:
            è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        try:
            source_path = self.config_dir / source_file
            target_path = self.config_dir / target_file
            
            # è¯»å–æºé…ç½®
            if not source_path.exists():
                logger.error(f"æºé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {source_file}")
                return False
            
            with open(source_path, 'r', encoding='utf-8') as f:
                source_config = yaml.safe_load(f)
            
            # è¯»å–ç›®æ ‡æ¨¡æ¿
            if not target_path.exists():
                logger.error(f"ç›®æ ‡é…ç½®æ¨¡æ¿ä¸å­˜åœ¨: {target_file}")
                return False
            
            with open(target_path, 'r', encoding='utf-8') as f:
                target_config = yaml.safe_load(f)
            
            # æ‰§è¡Œè¿ç§»
            migrated_config = self._perform_migration(source_config, target_config)
            
            # ä¿å­˜è¿ç§»åçš„é…ç½®
            backup_path = self.config_dir / f"{source_file}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            source_path.rename(backup_path)
            
            with open(source_path, 'w', encoding='utf-8') as f:
                yaml.dump(migrated_config, f, ensure_ascii=False, indent=2, sort_keys=False)
            
            logger.info(f"âœ… é…ç½®è¿ç§»æˆåŠŸ: {source_file} -> v2")
            logger.info(f"ğŸ“¦ åŸé…ç½®å¤‡ä»½: {backup_path.name}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®è¿ç§»å¤±è´¥: {e}")
            return False
    
    def _perform_migration(self, source: Dict[str, Any], target: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé…ç½®è¿ç§»"""
        # ä½¿ç”¨ç›®æ ‡é…ç½®ä½œä¸ºåŸºç¡€
        migrated = target.copy()
        
        # è¿ç§»æ˜ å°„è§„åˆ™
        migration_rules = {
            "system": "system",
            "data": "data", 
            "document_processing": "document_processing",
            "embedding": "embedding",
            "retrieval": "retrieval",
            "reranker": "reranker",
            "llm": "llm"
        }
        
        # æ‰§è¡Œå­—æ®µè¿ç§»
        for source_key, target_key in migration_rules.items():
            if source_key in source and target_key in migrated:
                migrated[target_key] = self._merge_configs(
                    migrated[target_key], source[source_key]
                )
        
        # æ›´æ–°å…ƒæ•°æ®
        migrated["config_metadata"]["last_updated"] = datetime.now().isoformat()
        migrated["config_metadata"]["migration_required"] = False
        
        return migrated
    
    def _merge_configs(self, target: Dict[str, Any], source: Dict[str, Any]) -> Dict[str, Any]:
        """åˆå¹¶é…ç½®å­—å…¸"""
        result = target.copy()
        
        for key, value in source.items():
            if key in result:
                if isinstance(result[key], dict) and isinstance(value, dict):
                    result[key] = self._merge_configs(result[key], value)
                else:
                    result[key] = value  # æºé…ç½®ä¼˜å…ˆ
            else:
                result[key] = value
        
        return result
